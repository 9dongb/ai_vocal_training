{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\rnehd\\.conda\\envs\\singking\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\rnehd\\AppData\\Local\\Temp\\ipykernel_29648\\2532743897.py:10: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa                                       # 음성 분석을 위함\n",
    "import threading                                     # 병렬처리를 위한 스레딩 모듈\n",
    "import numpy as np                                      \n",
    "import soundfile as sf\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import scipy.io.wavfile as wav\n",
    "from pydub.playback import play\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "from pydub import AudioSegment                       # 오디오를 처리를 위함\n",
    "import matplotlib.pyplot as plt                      # 그래프를 그리기 위함\n",
    "from scipy.interpolate import interp1d\n",
    "model = hub.load(\"https://tfhub.dev/google/spice/2\") # SPICE 모델 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 음정 주파수 추출 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPECTED_SAMPLE_RATE = 16000                                                                    # 지정할 Sample rate\n",
    "\n",
    "def extract_pitches(audio_path, duration):\n",
    "    original_y, sr = librosa.load(audio_path, mono=True, duration=duration)                     # SPICE모델은 mono 타입의 오디오만 지원\n",
    "\n",
    "    MAX_ABS_INT16 = 32768.0                                                                     # 16비트 PCM 형식에서 가능한 최대 절댓값을 나타내는 상수\n",
    "\n",
    "    y = original_y/float(MAX_ABS_INT16)                                                         # -1과 1사이의 부동 소수점으로 정규화\n",
    "\n",
    "    model_output = model.signatures[\"serving_default\"](tf.constant(y, tf.float32))              # 음정과 신뢰도를 얻음\n",
    "\n",
    "    pitch_outputs = model_output[\"pitch\"].numpy()                                               # 음정만 추출\n",
    "    \n",
    "    original_duration = len(y) / sr                                                             # 원래 신호의 전체 시간 (초)\n",
    "\n",
    "    pitch_time = np.linspace(0, original_duration, len(pitch_outputs))                          # 음정 출력의 시간 축 생성 (초 단위)\n",
    "    resampled_time = np.linspace(0, original_duration, int(original_duration))                  # 원곡 시간 축 생성 (초 단위)\n",
    "\n",
    "    interp_func = interp1d(pitch_time, pitch_outputs, kind='linear', fill_value=\"extrapolate\")  # 보간 함수 생성\n",
    "    \n",
    "    resampled_pitch_outputs = interp_func(resampled_time)                                       # 보간법 적용하여 음정 출력을 원래 신호의 길이에 맞춤\n",
    "\n",
    "    file_path = audio_path.replace('.wav', '.npy')                                              # 오디오 파일명과 같은 이름으로 npy 파일 생성\n",
    "\n",
    "    np.save(file_path, resampled_pitch_outputs)                                                 # 오디오 배열 저장\n",
    "\n",
    "    return original_y, resampled_pitch_outputs, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 사용자 음성 받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_name = '장범준-흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야.wav'\n",
    "\n",
    "artist_audio_path = f'assets/assets/audio/artist/{audio_name}'          # 원곡 음원 경로\n",
    "user_audio_path = f'assets/assets/audio/user/{audio_name}'              # 커버 음원 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "녹음 시작\n",
      "녹음 끝\n",
      "녹음 저장 완료: user_audio/flower-cover.wav\n"
     ]
    }
   ],
   "source": [
    "# 음원 파일 재생 함수\n",
    "def play_audio(audio_file):\n",
    "    song = AudioSegment.from_file(audio_file) # 오디오 파일 불러오기\n",
    "    play(song)                                # 오디오 파일 재생\n",
    "\n",
    "# 사용자 음성 녹음 함수\n",
    "def record_audio(duration, output_file, sync_delay=0):\n",
    "    fs = 44100                                # 샘플링 레이트\n",
    "    print(\"녹음 시작\")\n",
    "    recording = sd.rec(int((duration + sync_delay) * fs), samplerate=fs, channels=2, dtype='int16')\n",
    "    sd.wait()                                 # 녹음이 끝날 때까지 대기\n",
    "    print(\"녹음 끝\")\n",
    "    \n",
    "    # 지연 시간만큼 녹음된 파일에서 잘라내기\n",
    "    if sync_delay > 0:\n",
    "        recording = recording[int(sync_delay * fs):]\n",
    "    \n",
    "    wav.write(output_file, fs, recording)     # 녹음 저장(파일명, 샘플링 레이트, 음성 파일)\n",
    "    \n",
    "def record_and_play(artist_audio_path):\n",
    "\n",
    "    artist_audio = f'{artist_audio_path}.wav'                # \n",
    "    user_audio_path = f'user_audio/{audio_name}-cover.wav'   # 녹음된 사용자 음성을 저장할 경로\n",
    "    sync_delay = 0.4                                         # 음성 녹음 지연 시간 (초 단위)\n",
    "    \n",
    "    # 음원 파일 길이 가져오기\n",
    "    song = AudioSegment.from_file(artist_audio) # 음원 파일 불러오기\n",
    "    duration = len(song) / 1000.0               # 밀리초를 초 단위로 변환\n",
    "\n",
    "    # 스레드를 사용하여 동시에 재생 및 녹음 실행\n",
    "    playback_thread = threading.Thread(target=play_audio, args=(artist_audio,))                           # 스레드 생성(함수와 인자)\n",
    "    recording_thread = threading.Thread(target=record_audio, args=(duration, user_audio_path, sync_delay))\n",
    "\n",
    "    # 녹음과 재생을 동시에 시작\n",
    "    recording_thread.start()                   # 스레드 시작 (녹음)\n",
    "    playback_thread.start()                    # 스레드 시작 (재생)\n",
    "\n",
    "    playback_thread.join()                     # 스레드 종료 대기 (재생)\n",
    "    recording_thread.join()                    # 스레드 종료 대기 (녹음)\n",
    "\n",
    "    print(f\"녹음 저장 완료: {user_audio_path}\")\n",
    "\n",
    "record_and_play(artist_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_name = 'flower'                                                               # 노래 제목\n",
    "\n",
    "artist_audio_path = f'artist_audio/{audio_name}'                                    # 원곡 음원 경로\n",
    "\n",
    "user_audio_path = 'user_recording'                                                  # 커버 음원 경로\n",
    "\n",
    "y, sr =  librosa.load(f'{artist_audio_path}.wav', mono=True)\n",
    "duration = len(y)/sr\n",
    "\n",
    "artist_audio, resampled_artist_audio , sr = extract_pitches(f'{artist_audio_path}.wav', duration)\n",
    "user_audio, resampled_user_audio, _ = extract_pitches(f'{user_audio_path}.wav', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "singking",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
